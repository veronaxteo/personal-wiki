# right to privacy
## phil 121 - moral questions of data science, spring 2022

Suppose I am not aware that the search engine is making predictions about my medical records, sexual orientation, and religious beliefs and sharing them to third parties. Further, suppose the predictions are not anonymous; in other words, the search engine attaches my identity to the information that is found. Let us also assume that I do not deliberately try to hide certain information through my searches.

A complaint that I might have is that this act of storing and sharing personal information is a violation of my right to privacy such that it deprives me of my control over my self-presentation as well as what I choose to reveal about myself. I do not know what is being revealed to and to whom, which means that I am deprived of control to properly present myself in the way that I desire; I am deprived “over the ways in which [I] present different aspects of [myself] to others” (Marmor 7). When information such as my sexual orientation or religious beliefs is shared to third parties, it allows the people who know such information about me to make other judgements about my identity and also possibly form perceptions of me in ways that I either am uncomfortable with or do not want to be perceived as such. For example, if third parties such as potential future employers find out that I dropped out of college and that I have a chronic illness, they may make the assumption that I dropped out because of my medical condition, and would then think that I am not as capable of succeeding on the job as other job candidates, making it less likely that I get the job. But I do not know that they make this judgment, as I do not know what information they know and use. Whether I left college as a result of my medical condition or not, I may not want future employers to form judgements about my skills and potentials based on just my leaving college and illness; rather, I want them to interpret me as a hard-worker who continued to learn while away from college and someone who made a good, reflective choice in prioritizing my health, for instance. This example demonstrates how information about myself being stored and shared threatens the control over my self-presentation, as I am unable to attend to and reveal other important aspects of my identity for other people to interpret me as who I want to be interpreted as. Control over self-presentation is important because it allows me to “create and maintain different kinds of relationships with different people” (Marmor 8), and it allows me to adjust the amount of social scrutiny I invite into my life (Marmor 9). With the job example, by not allowing me to have control over how I present myself, I am unable to create positive impressions on employers, which hinders my ability to form the relationships that I would like in order to get the job. Further, by having my sexual orientation and religious beliefs—personal information that have large social connotations—revealed, I invite social scrutiny in ways that I may be uncomfortable with.

Now, suppose that the information provided to third parties is anonymous—the receivers of the information do not know who the information pertains to. This change weakens the complaint about the violation of the right to privacy due to the obstruction of my self-presentation. In this case, since there is not an identity attached to the information, it is hard to make the case that my right to privacy is violated. Control over self-presentation is not really a problem here, such that if the third parties do not have a way of figuring out who the data is referring to, my ability to present myself to other people in the way that I want is not compromised. I do not present myself in any particular way, and I also do not reveal information about myself, such that the third parties are unable to determine who the information is about. Third parties only have the information and cannot interpret me in a certain way without knowing that it is me. If, however, enough information is provided such that they are able to deduce that it is me, then the complaint about self-presentation might still be valid. Since the argument for the hindering of self-presentation is invalid in this situation, the general complaint about the violation of the right to privacy that relies on self-presentation is weakened.

Another possible complaint is that my right to privacy is violated because I have a right to myself as a person and my property: I have a right to my own personal information such as my sexual orientation or religious belief. According to Thomson, the right to privacy is a collection of other rights such as the right to person and property (Thomson 306). One interpretation of this is that a violation of the right to privacy is a kind of violation to the right of person or property. Sexual orientation and religious beliefs are pieces of information about myself that I come to discover and make part of my identity myself, and are not “owned” by anyone else. Thus, by predicting and sharing my personal information, both the right to my person and my right to privacy are violated; it is the right to person that the search engine and third parties violate, and it is this right “in virtue of the violation of which they violate [my] right to privacy” (Thomson 307). What makes this complaint stronger is that the information taken and used is deeply personal, information that explains a lot of who I am as a person. As Thomson also says, we do not “care nearly as much about our possessions as we care about ourselves” (Thomson 303). Sexual orientation and religious belief are information that I may not even be comfortable sharing with my friends and family, let alone strangers. Medical records, while perhaps might not necessarily be core parts of our identity, are still private pieces of information; information that I do not want others knowing without my permission. Thus, the search engine, in getting private information, accesses and uses my private information without consent. A worry, however, is that while it is my personal information, information that I supposedly own, I do not own the search engine—the search engine is not my property. This leads to the question of whether the right to my person is violated at all, since it is through the search engine that third parties receive my personal information, not through me.

Let us change the original scenario again by saying that I am careful about my searches, limiting my searches to ones that would likely not reveal much personal information about me, and that the search engine is determined and finds a way to get my information through manipulation, such as targeted advertisements. In this case, it seems that the first complaint about self-presentation might have more weight. I am deliberately not trying to have the search engine record, store, and analyze information that I do not want provided to third parties. This means that I am trying not to reveal certain pieces of information in an attempt to not present myself to third parties. I am not intending to reveal my personal information, so the third parties prying and getting access to my information deprives me of my control over what I choose to reveal. And highly sensitive information like sexual orientation, religious beliefs, and medical records is information that people often do not want others knowing or sharing, especially if they are unaware of who the information is being shared with and what types of information are shared.

The second complaint, that my right to privacy is violated because the right to my person and property is violated, would also have more weight. I am taking the proper steps to ensure that my information is not used and spread, which can be explained using Thomson’s argument on waiving rights. By taking necessary steps in an attempt to not reveal personal information, I do not waive the right for my information to be used and spread (Thomson 302). I did not waive my right or consent to my information being recorded, stored, and analyzed and made available to third parties, and I also did not consent to being scrutinized through manipulation. It is not just that my right to privacy is violated because the search engine or the people behind the search engine know information about me, but also that the information was obtained through deliberate manipulation. This aligns with Thomson’s view, in which she says that it’s not necessarily about what the information is (although the information here is arguably more personal), but how the information was obtained. The information was obtained and used without my permission, and in a way that goes against what I wanted and violates my right to privacy. However, it is also possible that I do not prevent my right from being waived, even if I do take the proper steps in to keep others from accessing my information. This is because I am trying to take the proper steps in someone else’s property; in other words, so long as I am using someone else’s product, nothing I do is protected, as it is not my property.